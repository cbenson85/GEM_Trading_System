name: Phase 3 Parallel Analysis - All Data Points

on:
  workflow_dispatch:
    inputs:
      mode:
        description: 'Analysis mode'
        required: true
        default: 'test'
        type: choice
        options:
          - test       # 10 stocks (5 batches Ã— 2 stocks)
          - small      # 50 stocks (10 batches Ã— 5 stocks)  
          - medium     # 200 stocks (10 batches Ã— 20 stocks)
          - full       # All 694 sustainable stocks (10 batches Ã— ~70 stocks)

permissions:
  contents: write

jobs:
  # Job 0: Split stocks into batches
  prepare-batches:
    runs-on: ubuntu-latest
    outputs:
      batch_count: ${{ steps.split.outputs.batch_count }}
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Split stocks into batches
      id: split
      run: |
        MODE="${{ github.event.inputs.mode }}"
        
        # Use sustainable_stocks.json for the 694 filtered stocks
        if [ "$MODE" = "test" ]; then
          echo "ðŸ“Š TEST MODE: Splitting 10 stocks into 5 batches (2 stocks each)"
          python phase3_batch_splitter.py Verified_Backtest_Data/sustainable_stocks.json --batches 5 --test
          echo "batch_count=5" >> $GITHUB_OUTPUT
        elif [ "$MODE" = "small" ]; then
          echo "ðŸ“Š SMALL MODE: Splitting 50 stocks into 10 batches (5 stocks each)"
          python phase3_batch_splitter.py Verified_Backtest_Data/sustainable_stocks.json --batches 10 --limit 50
          echo "batch_count=10" >> $GITHUB_OUTPUT
        elif [ "$MODE" = "medium" ]; then
          echo "ðŸ“Š MEDIUM MODE: Splitting 200 stocks into 10 batches (20 stocks each)"
          python phase3_batch_splitter.py Verified_Backtest_Data/sustainable_stocks.json --batches 10 --limit 200
          echo "batch_count=10" >> $GITHUB_OUTPUT
        else
          echo "ðŸ“Š FULL MODE: All 694 sustainable stocks into 10 batches"
          python phase3_batch_splitter.py Verified_Backtest_Data/sustainable_stocks.json --batches 10
          echo "batch_count=10" >> $GITHUB_OUTPUT
        fi
        
        # Show what was created
        echo ""
        echo "ðŸ“ Batch files created:"
        ls -lh batch_inputs/
    
    - name: Upload batch files as artifacts
      uses: actions/upload-artifact@v4
      with:
        name: batch-inputs
        path: batch_inputs/
  
  # Parallel Analysis Jobs - I'll create a matrix strategy for cleaner code
  analyze-batches:
    needs: prepare-batches
    runs-on: ubuntu-latest
    strategy:
      max-parallel: 10
      matrix:
        batch: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
    
    steps:
    - name: Check if batch should run
      id: check
      run: |
        if [ ${{ matrix.batch }} -le ${{ needs.prepare-batches.outputs.batch_count }} ]; then
          echo "should_run=true" >> $GITHUB_OUTPUT
        else
          echo "should_run=false" >> $GITHUB_OUTPUT
        fi
    
    - name: Checkout repository
      if: steps.check.outputs.should_run == 'true'
      uses: actions/checkout@v4
    
    - name: Set up Python
      if: steps.check.outputs.should_run == 'true'
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install enhanced dependencies
      if: steps.check.outputs.should_run == 'true'
      run: |
        pip install requests pandas numpy
        pip install beautifulsoup4 lxml
        pip install yfinance
        pip install pytrends
        pip install GoogleNews
    
    - name: Download batch files
      if: steps.check.outputs.should_run == 'true'
      uses: actions/download-artifact@v4
      with:
        name: batch-inputs
        path: batch_inputs/
    
    - name: Analyze Batch ${{ matrix.batch }}
      if: steps.check.outputs.should_run == 'true'
      env:
        POLYGON_API_KEY: ${{ secrets.POLYGON_API_KEY }}
      run: |
        echo "ðŸ”¬ Analyzing Batch ${{ matrix.batch }} with ALL data collectors..."
        python phase3_comprehensive_collector.py batch${{ matrix.batch }} batch_inputs/batch${{ matrix.batch }}_stocks.json
    
    - name: Upload results
      if: steps.check.outputs.should_run == 'true'
      uses: actions/upload-artifact@v4
      with:
        name: batch${{ matrix.batch }}-results
        path: Verified_Backtest_Data/phase3_batch_batch${{ matrix.batch }}_analysis.json
  
  # Merge all results
  merge-results:
    needs: analyze-batches
    if: always()
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Download all batch results
      uses: actions/download-artifact@v4
      with:
        pattern: batch*-results
        path: batch_results/
        merge-multiple: true
    
    - name: List downloaded results
      run: |
        echo "ðŸ“ Downloaded batch results:"
        ls -lh batch_results/
    
    - name: Merge batch results
      run: |
        echo "ðŸ”„ Merging all batch results..."
        python phase3_batch_merger.py batch_results/
    
    - name: Generate correlation matrix
      run: |
        echo "ðŸ“Š Building correlation matrix with ALL data points..."
        python phase3_correlation_analyzer.py Verified_Backtest_Data/phase3_merged_analysis.json
    
    - name: Display results summary
      run: |
        echo "## ðŸ“Š Phase 3 Enhanced Analysis Complete" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**Mode**: ${{ github.event.inputs.mode }}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        if [ -f "Verified_Backtest_Data/phase3_correlation_matrix.json" ]; then
          python -c "
import json
with open('Verified_Backtest_Data/phase3_correlation_matrix.json') as f:
    data = json.load(f)
    print('### Summary Statistics')
    print(f\"- Total Stocks Analyzed: {data.get('total_stocks', 0)}\")
    print(f\"- Successful Analyses: {data.get('successful_analyses', 0)}\")
    print()
    print('### Top Patterns Found')
    patterns = data.get('pattern_frequencies', {})
    sorted_patterns = sorted(patterns.items(), key=lambda x: x[1].get('frequency_percent', 0), reverse=True)
    for i, (pattern, info) in enumerate(sorted_patterns[:5], 1):
        print(f\"{i}. **{pattern}**: {info.get('frequency_percent', 0):.1f}% frequency\")
          " >> $GITHUB_STEP_SUMMARY
        fi
    
    - name: Commit results
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "Phase 3 Enhanced Bot"
        
        # Add batch inputs and results
        git add batch_inputs/ 2>/dev/null || true
        git add Verified_Backtest_Data/phase3_*.json
        
        git diff --staged --quiet || git commit -m "ðŸ”¬ Phase 3 Enhanced Analysis: ${{ github.event.inputs.mode }} mode
        
        Analyzed stocks with ALL 150+ data points
        Mode: ${{ github.event.inputs.mode }}
        Date: $(date +'%Y-%m-%d %H:%M')"
        
        git pull origin main --rebase --autostash
    
    - name: Push changes
      uses: ad-m/github-push-action@master
      with:
        github_token: ${{ secrets.GITHUB_TOKEN }}
        branch: main
