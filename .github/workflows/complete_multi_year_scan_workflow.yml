name: Complete Multi-Year Scan (Auto-Merge)

on:
  workflow_dispatch:
    inputs:
      confirmation:
        description: 'Type "RUN" to start all 4 scans (will take ~1.5 hours total)'
        required: true
        default: ''

jobs:
  scan_2010_2013:
    name: Scan 2010-2013
    runs-on: ubuntu-latest
    if: ${{ github.event.inputs.confirmation == 'RUN' }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
      
      - name: Install dependencies
        run: pip install requests yfinance
      
      - name: Create output directory
        run: mkdir -p Verified_Backtest_Data
      
      - name: Run scan
        env:
          POLYGON_API_KEY: ${{ secrets.POLYGON_API_KEY }}
        run: |
          python explosive_stock_scanner.py --start-year 2010 --end-year 2013
      
      - name: Upload results
        uses: actions/upload-artifact@v4
        with:
          name: catalog-2010-2013
          path: Verified_Backtest_Data/explosive_stocks_catalog.json

  scan_2014_2017:
    name: Scan 2014-2017
    runs-on: ubuntu-latest
    if: ${{ github.event.inputs.confirmation == 'RUN' }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
      
      - name: Install dependencies
        run: pip install requests yfinance
      
      - name: Create output directory
        run: mkdir -p Verified_Backtest_Data
      
      - name: Run scan
        env:
          POLYGON_API_KEY: ${{ secrets.POLYGON_API_KEY }}
        run: |
          python explosive_stock_scanner.py --start-year 2014 --end-year 2017
      
      - name: Upload results
        uses: actions/upload-artifact@v4
        with:
          name: catalog-2014-2017
          path: Verified_Backtest_Data/explosive_stocks_catalog.json

  scan_2018_2021:
    name: Scan 2018-2021
    runs-on: ubuntu-latest
    if: ${{ github.event.inputs.confirmation == 'RUN' }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
      
      - name: Install dependencies
        run: pip install requests yfinance
      
      - name: Create output directory
        run: mkdir -p Verified_Backtest_Data
      
      - name: Run scan
        env:
          POLYGON_API_KEY: ${{ secrets.POLYGON_API_KEY }}
        run: |
          python explosive_stock_scanner.py --start-year 2018 --end-year 2021
      
      - name: Upload results
        uses: actions/upload-artifact@v4
        with:
          name: catalog-2018-2021
          path: Verified_Backtest_Data/explosive_stocks_catalog.json

  scan_2022_2024:
    name: Scan 2022-2024
    runs-on: ubuntu-latest
    if: ${{ github.event.inputs.confirmation == 'RUN' }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
      
      - name: Install dependencies
        run: pip install requests yfinance
      
      - name: Create output directory
        run: mkdir -p Verified_Backtest_Data
      
      - name: Run scan
        env:
          POLYGON_API_KEY: ${{ secrets.POLYGON_API_KEY }}
        run: |
          python explosive_stock_scanner.py --start-year 2022 --end-year 2024
      
      - name: Upload results
        uses: actions/upload-artifact@v4
        with:
          name: catalog-2022-2024
          path: Verified_Backtest_Data/explosive_stocks_catalog.json

  merge_and_filter:
    name: Merge All Scans + Run Filters
    runs-on: ubuntu-latest
    needs: [scan_2010_2013, scan_2014_2017, scan_2018_2021, scan_2022_2024]
    if: ${{ always() && github.event.inputs.confirmation == 'RUN' }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
      
      - name: Create directories
        run: mkdir -p Verified_Backtest_Data
      
      - name: Download 2010-2013 catalog
        uses: actions/download-artifact@v4
        with:
          name: catalog-2010-2013
          path: temp/2010-2013/
      
      - name: Download 2014-2017 catalog
        uses: actions/download-artifact@v4
        with:
          name: catalog-2014-2017
          path: temp/2014-2017/
      
      - name: Download 2018-2021 catalog
        uses: actions/download-artifact@v4
        with:
          name: catalog-2018-2021
          path: temp/2018-2021/
      
      - name: Download 2022-2024 catalog
        uses: actions/download-artifact@v4
        with:
          name: catalog-2022-2024
          path: temp/2022-2024/
      
      - name: Merge all catalogs
        run: |
          python3 << 'EOF'
          import json
          import glob
          from datetime import datetime
          
          print("\n" + "="*60)
          print("MERGING ALL SCAN CATALOGS")
          print("="*60 + "\n")
          
          # Find all catalog files
          catalog_files = glob.glob('temp/**/explosive_stocks_catalog.json', recursive=True)
          catalog_files.sort()
          
          print(f"Found {len(catalog_files)} catalog files:")
          for f in catalog_files:
              print(f"  - {f}")
          
          if len(catalog_files) == 0:
              print("\n‚ùå No catalog files found!")
              exit(1)
          
          # Load all catalogs
          all_stocks = []
          total_scanned = 0
          total_errors = 0
          total_api_calls = 0
          earliest_start = None
          latest_end = None
          
          for catalog_file in catalog_files:
              with open(catalog_file, 'r') as f:
                  data = json.load(f)
                  stocks = data.get('stocks', [])
                  scan_info = data.get('scan_info', {})
                  
                  print(f"\n‚úÖ Loaded: {catalog_file}")
                  print(f"   Stocks: {len(stocks)}")
                  print(f"   Period: {scan_info.get('scan_period_start')} to {scan_info.get('scan_period_end')}")
                  
                  all_stocks.extend(stocks)
                  total_scanned += scan_info.get('total_stocks_scanned', 0)
                  total_errors += scan_info.get('data_errors', 0)
                  total_api_calls += scan_info.get('api_calls_made', 0)
                  
                  start = scan_info.get('scan_period_start')
                  end = scan_info.get('scan_period_end')
                  if earliest_start is None or (start and start < earliest_start):
                      earliest_start = start
                  if latest_end is None or (end and end > latest_end):
                      latest_end = end
          
          # Remove duplicates
          seen = set()
          unique_stocks = []
          for stock in all_stocks:
              key = f"{stock['ticker']}_{stock['year_discovered']}"
              if key not in seen:
                  unique_stocks.append(stock)
                  seen.add(key)
          
          # Sort by gain percent
          unique_stocks.sort(key=lambda x: x.get('gain_percent', 0), reverse=True)
          
          print(f"\nüìä Merge Summary:")
          print(f"   Total stocks found: {len(all_stocks)}")
          print(f"   Unique stocks: {len(unique_stocks)}")
          print(f"   Duplicates removed: {len(all_stocks) - len(unique_stocks)}")
          print(f"   Tickers scanned: {total_scanned:,}")
          
          # Create merged catalog
          merged_catalog = {
              'scan_info': {
                  'scan_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                  'scan_period_start': earliest_start or 'Unknown',
                  'scan_period_end': latest_end or 'Unknown',
                  'criteria': '500%+ gain in any 120-day window',
                  'data_sources': ['Polygon API', 'Yahoo Finance'],
                  'coverage': 'Complete - all active US stock tickers (2010-2024)',
                  'total_stocks_scanned': total_scanned,
                  'total_explosive_stocks_found': len(unique_stocks),
                  'data_errors': total_errors,
                  'api_calls_made': total_api_calls,
                  'scan_complete': True,
                  'merged_from_scans': len(catalog_files)
              },
              'stocks': unique_stocks,
              'metadata': {
                  'last_updated': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                  'verified_by': 'Merged from 4 parallel GitHub Actions scans',
                  'quality_checks_passed': True,
                  'notes': f'Complete 2010-2024 coverage via {len(catalog_files)} separate year-range scans'
              }
          }
          
          # Save
          with open('Verified_Backtest_Data/explosive_stocks_catalog.json', 'w') as f:
              json.dump(merged_catalog, f, indent=2)
          
          print(f"\n‚úÖ Merged catalog saved!")
          print(f"\nüöÄ Top 10 Explosive Stocks:")
          for i, stock in enumerate(unique_stocks[:10], 1):
              print(f"   {i:2d}. {stock['ticker']:6s}: {stock['gain_percent']:>7.0f}% in {stock['days_to_peak']:>3d} days ({stock['year_discovered']})")
          EOF
      
      - name: Run COVID Filter
        run: |
          echo "üîç Running COVID filter..."
          python filter_covid_era.py
      
      - name: Run Sustainability Filter
        run: |
          echo "üîç Running sustainability filter..."
          python filter_sustainability.py
      
      - name: Display final results
        run: |
          python3 << 'EOF'
          import json
          import os
          
          print("\n" + "="*60)
          print("üìä FINAL RESULTS (2010-2024)")
          print("="*60 + "\n")
          
          # Merged catalog
          with open('Verified_Backtest_Data/explosive_stocks_catalog.json', 'r') as f:
              catalog = json.load(f)
              info = catalog['scan_info']
              print(f"üìÑ Complete Catalog:")
              print(f"   Period: {info['scan_period_start']} to {info['scan_period_end']}")
              print(f"   Total explosive stocks: {info['total_explosive_stocks_found']:,}")
              print(f"   Tickers scanned: {info['total_stocks_scanned']:,}")
              print(f"   API calls: {info['api_calls_made']:,}")
          
          # COVID filtered
          with open('Verified_Backtest_Data/explosive_stocks_CLEAN.json', 'r') as f:
              clean = json.load(f)
              print(f"\nüìÑ After COVID Filter:")
              print(f"   CLEAN stocks (non-COVID): {len(clean.get('stocks', []))}")
          
          with open('Verified_Backtest_Data/explosive_stocks_COVID_ERA.json', 'r') as f:
              covid = json.load(f)
              print(f"   COVID-era stocks (2020-2021): {len(covid.get('stocks', []))}")
          
          # Sustainability filtered
          with open('Verified_Backtest_Data/explosive_stocks_CLEAN.json', 'r') as f:
              final = json.load(f)
              print(f"\nüìÑ After Sustainability Filter:")
              print(f"   Sustainable stocks (FINAL): {len(final.get('stocks', []))}")
          
          if os.path.exists('Verified_Backtest_Data/explosive_stocks_UNSUSTAINABLE.json'):
              with open('Verified_Backtest_Data/explosive_stocks_UNSUSTAINABLE.json', 'r') as f:
                  unsustainable = json.load(f)
                  print(f"   Pump-and-dumps removed: {len(unsustainable.get('stocks', []))}")
          
          print(f"\n‚úÖ Complete 2010-2024 analysis finished!")
          print(f"üì¶ Download 'final-results-2010-2024' artifact for all files")
          EOF
      
      - name: Upload final results
        uses: actions/upload-artifact@v4
        with:
          name: final-results-2010-2024
          path: |
            Verified_Backtest_Data/explosive_stocks_catalog.json
            Verified_Backtest_Data/explosive_stocks_CLEAN.json
            Verified_Backtest_Data/explosive_stocks_COVID_ERA.json
            Verified_Backtest_Data/explosive_stocks_UNSUSTAINABLE.json
            Verified_Backtest_Data/filter_summary.json
          retention-days: 90
