# GEM Trading System - AI Catch-Up Prompt
**Last Updated**: 2025-11-02 03:15:00
**System Version**: 5.0.1-REBUILD
**Current Phase**: Phase 2: System Requirements & Data Infrastructure - COMPLETE ‚úÖ

---

## üéØ CRITICAL CONTEXT

### What You're Walking Into
System rebuilt from ground up after previous model fabricated backtest data. All infrastructure now complete and verified. Ready for Phase 3.

### Immediate Priority
Begin Phase 3: Deep-dive pre-catalyst analysis on 170 clean explosive stocks

---

## üìä SYSTEM STATUS

### Current State
- **Portfolio**: CLEARED - Starting fresh
- **Cash Available**: $10,000 (reset)
- **System Stage**: Infrastructure Complete - Ready for Analysis
- **Last Completed Phase**: Phase 2: System Requirements & Data Infrastructure - COMPLETE ‚úÖ
- **Next Phase**: Phase 3: Stock Discovery & Pre-Catalyst Analysis

### Data Verification Status

- Current Prices: ‚úÖ VERIFIED (Polygon API)
- Volume Data: ‚úÖ VERIFIED (Polygon API)
- Float Data: ‚ö†Ô∏è PARTIAL (Polygon API - not all stocks)
- Explosive Stock Catalog: ‚úÖ VERIFIED (244 stocks found, 170 clean, 69 COVID-era)
- Backtest Infrastructure: ‚úÖ COMPLETE
- Data Backup System: ‚úÖ FIXED (merge logic implemented)
- Historical Analysis: ‚ùå NOT YET STARTED (Phase 3)

---

## üóÇÔ∏è FILE STRUCTURE & LOCATIONS

**Repository**: https://github.com/cbenson85/GEM_Trading_System

### Core System Files (VERIFIED)

- `/Current_System/GEM_v5_Master_Screening_Protocol.md` - Core screening rules
- `/Current_System/Trading_Rules_Complete.md` - Trading operations guide
- `/FILE_VERIFICATION_PROTOCOL.md` - File access methodology (MANDATORY)
- `/COVID_ERA_EXCLUSION_RULE.md` - Critical COVID-era filter rule

### Data Files (VERIFIED - Location & Status)

- `/Verified_Backtest_Data/explosive_stocks_catalog.json` - ‚úÖ Latest scan results
- `/Verified_Backtest_Data/explosive_stocks_CLEAN.json` - ‚úÖ 170 clean stocks (2014-2019, 2022-2024)
- `/Verified_Backtest_Data/explosive_stocks_COVID_ERA.json` - ‚úÖ 69 COVID-era stocks (archived)
- `/Verified_Backtest_Data/refinement_history.json` - ‚úÖ System evolution log
- `/Verified_Backtest_Data/README.md` - ‚úÖ Data quality standards
- `/Verified_Backtest_Data/filter_summary.json` - ‚ùå TO BE CREATED (next filter run)
- `/Verified_Backtest_Data/pre_catalyst_analysis/` - ‚ùå TO BE CREATED (Phase 3)
- `/Verified_Backtest_Data/backtest_runs/` - ‚ùå TO BE CREATED (Phase 4+)

### Active Scripts (VERIFIED)

- `/explosive_stock_scanner.py` - ‚úÖ 10-year scanner (GitHub Actions)
- `/filter_covid_era.py` - ‚úÖ COVID filter WITH MERGE LOGIC (updated 2025-11-02)
- `/.github/workflows/explosive_stock_scan_workflow.yml` - ‚úÖ Automation workflow

### Archived Content (DO NOT USE FOR DECISIONS)

- `/Archive_Unverified/` - ‚úÖ Contains old unverified data (reference only)
- `/Backtest_Results/` - ‚ö†Ô∏è UNVERIFIED (framework reference only)
- `/Strategy_Evolution/` - ‚ö†Ô∏è UNVERIFIED (concepts only, not data)

### üìÇ Complete GitHub File Catalog

**Full catalog with all links**: [GITHUB_FILE_CATALOG.md](https://raw.githubusercontent.com/cbenson85/GEM_Trading_System/refs/heads/main/GITHUB_FILE_CATALOG.md)

**Critical files for AI:**
- [CURRENT_CATCHUP_PROMPT.md](https://raw.githubusercontent.com/cbenson85/GEM_Trading_System/refs/heads/main/System_State/CURRENT_CATCHUP_PROMPT.md) - This file
- [system_state.json](https://raw.githubusercontent.com/cbenson85/GEM_Trading_System/refs/heads/main/System_State/system_state.json) - System data
- [FILE_VERIFICATION_PROTOCOL.md](https://raw.githubusercontent.com/cbenson85/GEM_Trading_System/refs/heads/main/FILE_VERIFICATION_PROTOCOL.md) - File access method

---

## üî¨ BACKTESTING METHODOLOGY

### Approach

1. ‚úÖ Find stocks with 500%+ gains in any 6-month window (last 10 years) - COMPLETE
2. ‚ùå Deep dive into 180 days PRE-CATALYST for each stock - Phase 3
3. ‚ùå Analyze: price, volume, sentiment, leadership, news, patterns - Phase 3
4. ‚ùå Identify correlations between explosive stocks - Phase 3
5. ‚ùå Build screener based on correlations - Phase 3+
6. ‚ùå Backtest on random historical dates - Phase 4+
7. ‚ùå Apply FALSE MISS principle to discarded stocks - Phase 4+
8. ‚ùå Track picks AND discards with full performance data - Phase 4+
9. ‚ùå Refine until consistent 10-year performance - Phase 4+
10. ‚úÖ Store ALL data for future refinement - Infrastructure ready

### Current Progress

**Phase 1**: Discovery & Documentation Audit - ‚úÖ COMPLETE
**Phase 2**: System Requirements & Data Infrastructure - ‚úÖ COMPLETE
- ‚úÖ 10-year explosive stock scan complete (244 stocks)
- ‚úÖ COVID-era filter applied (170 clean, 69 archived)
- ‚úÖ File verification protocol established
- ‚úÖ Data backup system fixed (merge logic)
- ‚úÖ All infrastructure verified and working

**Phase 3**: Stock Discovery & Pre-Catalyst Analysis - ‚ùå NOT STARTED
- ‚ùå Deep-dive 180-day pre-catalyst analysis
- ‚ùå Pattern discovery across 170 clean stocks
- ‚ùå Correlation matrix building
- ‚ùå Screener criteria extraction

### Data Sources

- Price/Volume: Polygon API (Developer tier) + Yahoo Finance backup
- News/Sentiment: Web scraping (Google, Yahoo Finance)
- Insider Trading: Free sources (Finviz, OpenInsider, SEC Form 4)
- SEC Filings: SEC EDGAR (free)
- Float/Shares: Polygon API + manual verification

---

## üìà DISCOVERED PATTERNS

### Verified Correlations
NONE YET - Will be discovered during Phase 3 analysis

### Current Scoring Criteria
CURRENT v5.0.1 CRITERIA - Will be updated based on Phase 3 pattern discovery

### Refinement History
2 refinements logged:
1. System reset (2025-11-01) - Cleared unverified data
2. COVID-era exclusion rule (2025-11-01) - Exclude 2020-2021 from patterns

---

## üéØ DECISIONS MADE

### Key Decisions
1. ‚úÖ Mark all previous backtest results as UNVERIFIED
2. ‚úÖ Clear all current portfolio positions - starting fresh
3. ‚úÖ Build from verified data only - no fabrication
4. ‚úÖ Use 500%+ in 6 months as explosive stock criteria
5. ‚úÖ Analyze 180 days pre-catalyst for pattern discovery
6. ‚úÖ Store all backtest data (picks AND discards) for refinement
7. ‚úÖ Apply false miss principle in all backtests
8. ‚úÖ User only does copy/paste - full automation required
9. ‚úÖ Free data sources only (no paid APIs except Polygon)
10. ‚úÖ Exclude COVID-era (2020-2021) from pattern analysis
11. ‚úÖ Implement merge logic in filter to prevent data loss

### Rules Established
1. **NO FABRICATION** - Verify or say you can't
2. **FALSE MISS CHECK** - Always check discarded stocks for explosive growth
3. **STORE EVERYTHING** - All decisions, data, refinements must be saved
4. **COPY/PASTE ONLY** - User should never manually enter data
5. **10-YEAR VALIDATION** - System must prove consistency before live trading
6. **FILE VERIFICATION** - Every file must be verified using the established protocol
7. **DATA PRESERVATION** - Filter script uses merge logic (no data loss on subsequent scans)

---

## üìù WHAT NEEDS TO HAPPEN NEXT

### Phase 3 Tasks (READY TO BEGIN)
1. Create pre-catalyst analysis framework
2. Deep-dive analyze 170 clean explosive stocks (180 days before explosion)
3. Extract common patterns across successful stocks
4. Build correlation matrix
5. Identify screening criteria based on patterns
6. Document all findings in /Verified_Backtest_Data/

### Blockers/Questions
NONE - All infrastructure complete, ready to proceed

---

## üîó IMPORTANT LINKS

- **GitHub Repo**: https://github.com/cbenson85/GEM_Trading_System
- **Polygon API**: Developer tier (key: pvv6DNmKAoxojCc0B5HOaji6I_k1egv0)
- **Data Storage**: /Verified_Backtest_Data/ (active and verified)
- **File Catalog**: [GITHUB_FILE_CATALOG.md](https://raw.githubusercontent.com/cbenson85/GEM_Trading_System/refs/heads/main/GITHUB_FILE_CATALOG.md)

---

## üîê FILE VERIFICATION PROTOCOL (MANDATORY)

### **The Problem We Solved:**
AI was creating files without verifying it could read them back from GitHub. This created broken links and lost context between sessions.

### **The Solution - REQUIRED WORKFLOW:**

**When AI Creates New File(s):**

**Step 1**: AI provides files & posts to catalog
- Create file(s) with download links
- Provide file information (location, purpose, contents)
- Immediately update GITHUB_FILE_CATALOG.md with ‚è≥ PENDING status

**Step 2**: AI constructs & posts URLs
- Construct raw GitHub URL(s): `https://raw.githubusercontent.com/cbenson85/GEM_Trading_System/refs/heads/main/[FILE_PATH]`
- Post URLs in plain text for easy copying
- Say: "Copy these URLs and paste them back after upload:"

**Step 3**: User uploads & pastes URLs back
- User uploads file(s) to GitHub
- User copies the URL(s) from chat
- User pastes them back in chat

**Step 4**: AI verifies files
- AI uses web_fetch on each pasted URL
- AI confirms file contents
- AI updates GITHUB_FILE_CATALOG.md with ‚úÖ VERIFIED status
- AI updates CURRENT_CATCHUP_PROMPT.md if needed

### **Critical Rules:**
- ‚ùå **AI CANNOT** fetch raw GitHub URLs directly without user providing them first
- ‚úÖ **AI CAN** fetch URLs that user pastes back
- üîÑ **EVERY file** created must follow this verification workflow
- üìù **EVERY verification** updates the catalog and this prompt
- üö´ **NO EXCEPTIONS** - If file isn't verified, it doesn't exist to AI

**Full Documentation:** [FILE_VERIFICATION_PROTOCOL.md](https://raw.githubusercontent.com/cbenson85/GEM_Trading_System/refs/heads/main/FILE_VERIFICATION_PROTOCOL.md)

---

## üîÑ DATA BACKUP SYSTEM (FIXED 2025-11-02)

### **The Problem:**
Original filter script OVERWROTE CLEAN.json and COVID.json files on each run, causing data loss when incremental scans ran.

### **The Solution:**
Updated `filter_covid_era.py` with **MERGE LOGIC**:

**How It Works:**
1. Filter loads existing CLEAN.json and COVID.json (if they exist)
2. Filter reads new stocks from catalog.json
3. Filter merges new stocks (checks for ticker+year duplicates)
4. Filter saves updated cumulative files

**Result:**
- ‚úÖ No data loss on subsequent scans
- ‚úÖ No duplicates (ticker+year key)
- ‚úÖ Accumulates findings over time
- ‚úÖ catalog.json remains "latest scan snapshot"

**Example:**
```
Scan 1 (Full 10-year): catalog.json (244 stocks)
‚Üí Filter: CLEAN.json (170) + COVID.json (69)

Scan 2 (Just 2024): catalog.json (1 stock)
‚Üí Filter: Loads existing 170, adds 1 new = 171 total
         (or skips if duplicate)

No data loss! ‚úÖ
```

---

## üíæ PROGRESS LOG

**2025-11-01 02:09** - Phase 1 Complete
- Action: Completed audit of existing system
- Result: Identified fabricated backtest data, cleared portfolio, established new methodology

**2025-11-01** - Phase 2 Started
- Action: Building catch-up prompt system and data infrastructure
- Result: System architecture defined

**2025-11-01** - 10-Year Scan Complete
- Action: Ran full explosive stock scan (2014-2024)
- Result: 244 explosive stocks found, filtered to 170 clean + 69 COVID-era

**2025-11-02** - File Verification Protocol Complete
- Action: Established and documented file verification workflow
- Result: Zero broken links, perfect file continuity

**2025-11-02** - Data Backup System Fixed
- Action: Updated filter script with merge logic
- Result: Data accumulates safely, no loss on subsequent scans

**2025-11-02 03:15** - Phase 2 Complete ‚úÖ
- Action: All infrastructure verified and working
- Result: Ready to begin Phase 3 pre-catalyst analysis

---

## ‚ö†Ô∏è CRITICAL REMINDERS

1. **NO FABRICATION**: All data must be verified. If unsure, say so immediately.
2. **FALSE MISS PRINCIPLE**: When backtesting, check discarded stocks for explosive growth
3. **USER DOES COPY/PASTE ONLY**: All automation, no manual data entry for user
4. **STORE EVERYTHING**: All backtest data, decisions, refinements must be saved
5. **10-YEAR VALIDATION**: System must work consistently across 10 years before live use
6. **FILE VERIFICATION**: Every file must be verified using the protocol above
7. **DATA PRESERVATION**: Filter uses merge logic - existing data is never lost

---

## üöÄ HOW TO CONTINUE

1. Read this entire prompt
2. Ask clarifying questions if anything is unclear
3. Confirm you understand current state and next phase
4. Wait for user approval before proceeding with Phase 3
5. Update this prompt after each phase completion
6. **VERIFY FILES**: Follow verification protocol for any new files

---

## üìä READY FOR PHASE 3

**What We Have:**
- ‚úÖ 170 clean explosive stocks (2014-2019, 2022-2024)
- ‚úÖ 69 COVID-era stocks archived (2020-2021)
- ‚úÖ Complete data infrastructure
- ‚úÖ File verification system working
- ‚úÖ Data backup system working
- ‚úÖ All tools and scripts verified

**What We Need to Do:**
- ‚ùå Analyze 180 days PRE-CATALYST for each of 170 stocks
- ‚ùå Extract common patterns and correlations
- ‚ùå Build screening criteria based on findings
- ‚ùå Document all discoveries

**Estimated Time for Phase 3:**
- Deep analysis: 2-3 weeks of systematic work
- Pattern discovery: Iterative process
- Output: Correlation matrix + screener criteria

---

**END OF CATCH-UP PROMPT**
Generated by: GEM Catch-Up Prompt System v2.0 (with File Verification Protocol)
Last Updated: 2025-11-02 03:15:00
System Status: Phase 2 Complete - Ready for Phase 3
