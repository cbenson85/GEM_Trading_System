#!/usr/bin/env python3
"""
Phase 3 Comprehensive Data Collector - Gathers ALL data points per stock
Designed for parallel processing to avoid 6-hour timeout
"""

import json
import os
import sys
import requests
from datetime import datetime, timedelta
from typing import Dict, List, Tuple
import time

class ComprehensiveStockAnalyzer:
    def __init__(self, polygon_api_key=None):
        self.api_key = polygon_api_key or os.environ.get('POLYGON_API_KEY', 'pvv6DNmKAoxojCc0B5HOaji6I_k1egv0')
        self.base_url = 'https://api.polygon.io'
        
    def analyze_stock(self, stock: Dict) -> Dict:
        """
        Analyze a single stock and gather ALL data points
        Returns dictionary with 150+ metrics
        """
        ticker = stock.get('ticker')
        entry_date = stock.get('entry_date')
        entry_price = stock.get('entry_price', 0)
        
        print(f"\n{'='*60}")
        print(f"Analyzing {ticker}")
        print(f"{'='*60}")
        
        # Initialize result structure
        result = {
            # 1. Basic Stock Data (copy from input)
            'ticker': ticker,
            'year_discovered': stock.get('year_discovered', stock.get('year')),
            'entry_date': entry_date,
            'entry_price': entry_price,
            'catalyst_date': stock.get('catalyst_date'),
            'peak_price': stock.get('peak_price'),
            'gain_percent': stock.get('gain_percent'),
            'days_to_peak': stock.get('days_to_peak'),
            'sector': stock.get('sector', 'Unknown'),
            'data_source': stock.get('data_source', 'Polygon'),
            
            # 2. Sustainability Metrics (if available)
            'sustainability_stats': stock.get('sustainability_stats', {}),
            
            # Will be populated by analysis
            'price_volume_patterns': {},
            'technical_indicators': {},
            'market_context': {},
            'pattern_scores': {},
            'analysis_timestamp': datetime.now().isoformat(),
            'analysis_status': 'starting'
        }
        
        if not entry_date or not ticker:
            result['analysis_status'] = 'error_missing_data'
            return result
        
        try:
            # Get 90-day price data before explosion
            price_data = self.get_price_data(ticker, entry_date, 90)
            
            if price_data and len(price_data) > 20:
                # 3. Price & Volume Patterns
                result['price_volume_patterns'] = self.analyze_price_volume(price_data, entry_price)
                
                # 4. Technical Indicators
                result['technical_indicators'] = self.calculate_technicals(price_data)
                
                # 5. Market Context (vs SPY/QQQ)
                result['market_context'] = self.analyze_market_context(ticker, entry_date, price_data)
                
                # 6. Pattern Scoring
                result['pattern_scores'] = self.calculate_pattern_scores(
                    result['price_volume_patterns'],
                    result['technical_indicators'],
                    result['market_context']
                )
                
                result['analysis_status'] = 'complete'
                result['data_quality'] = 'good' if len(price_data) > 60 else 'acceptable'
            else:
                result['analysis_status'] = 'insufficient_data'
                result['data_quality'] = 'poor'
                
        except Exception as e:
            result['analysis_status'] = 'error'
            result['error_message'] = str(e)
            print(f"  ‚ùå Error analyzing {ticker}: {e}")
        
        return result
    
    def get_price_data(self, ticker: str, entry_date: str, days_before: int = 90):
        """Fetch OHLC data for specified period"""
        try:
            # Calculate date range
            end_dt = datetime.strptime(entry_date, '%Y-%m-%d')
            start_dt = end_dt - timedelta(days=days_before)
            
            start_date = start_dt.strftime('%Y-%m-%d')
            end_date = end_dt.strftime('%Y-%m-%d')
            
            print(f"  üìä Fetching {ticker} data: {start_date} to {end_date}")
            
            url = f"{self.base_url}/v2/aggs/ticker/{ticker}/range/1/day/{start_date}/{end_date}"
            params = {'apiKey': self.api_key, 'adjusted': 'true', 'sort': 'asc'}
            
            response = requests.get(url, params=params, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                if data.get('status') == 'OK' and data.get('results'):
                    print(f"  ‚úÖ Got {len(data['results'])} days of data")
                    return data['results']
            
            print(f"  ‚ö†Ô∏è No data available for {ticker}")
            return []
            
        except Exception as e:
            print(f"  ‚ùå Error fetching data: {e}")
            return []
    
    def analyze_price_volume(self, price_data: List[Dict], entry_price: float) -> Dict:
        """Analyze price and volume patterns"""
        print(f"  üîç Analyzing price/volume patterns...")
        
        patterns = {
            # Volume metrics
            'volume_avg_20d': 0,
            'volume_avg_50d': 0,
            'volume_spike_count': 0,
            'volume_spike_max': 0,
            'volume_spike_dates': [],
            'volume_3x_spike': False,
            'volume_5x_spike': False,
            'volume_10x_spike': False,
            'volume_acceleration': 0,
            
            # Price patterns
            'breakout_20d_high': False,
            'breakout_52w_high': False,
            'double_bottom': False,
            'ascending_triangle': False,
            'flag_pattern': False,
            'higher_lows_count': 0,
            'narrowing_range': False,
            'accumulation_detected': False
        }
        
        if len(price_data) < 20:
            return patterns
        
        # Calculate volume metrics
        volumes = [d.get('v', 0) for d in price_data]
        closes = [d.get('c', 0) for d in price_data]
        highs = [d.get('h', 0) for d in price_data]
        lows = [d.get('l', 0) for d in price_data]
        
        # Volume averages
        patterns['volume_avg_20d'] = sum(volumes[-20:]) / 20 if len(volumes) >= 20 else sum(volumes) / len(volumes)
        patterns['volume_avg_50d'] = sum(volumes[-50:]) / 50 if len(volumes) >= 50 else sum(volumes) / len(volumes)
        
        # Volume spike detection
        if patterns['volume_avg_20d'] > 0:
            for i, vol in enumerate(volumes[-30:]):  # Check last 30 days
                spike_ratio = vol / patterns['volume_avg_20d']
                if spike_ratio >= 3:
                    patterns['volume_spike_count'] += 1
                    patterns['volume_3x_spike'] = True
                    if spike_ratio >= 5:
                        patterns['volume_5x_spike'] = True
                    if spike_ratio >= 10:
                        patterns['volume_10x_spike'] = True
                    if spike_ratio > patterns['volume_spike_max']:
                        patterns['volume_spike_max'] = spike_ratio
        
        # Price patterns
        if len(closes) >= 20:
            twenty_high = max(highs[-20:])
            if closes[-1] > twenty_high * 0.98:  # Within 2% of 20-day high
                patterns['breakout_20d_high'] = True
        
        if len(closes) >= 52*5:  # Approximate year of trading days
            year_high = max(highs)
            if closes[-1] > year_high * 0.98:
                patterns['breakout_52w_high'] = True
        
        # Higher lows detection
        for i in range(1, min(10, len(lows))):
            if lows[-i] > lows[-i-1]:
                patterns['higher_lows_count'] += 1
        
        # Accumulation pattern (flat price + rising volume)
        if len(closes) >= 20 and len(volumes) >= 20:
            price_range = (max(closes[-20:]) - min(closes[-20:])) / min(closes[-20:])
            vol_trend = (sum(volumes[-10:]) / 10) / (sum(volumes[-20:-10]) / 10)
            if price_range < 0.15 and vol_trend > 1.5:  # Flat price, rising volume
                patterns['accumulation_detected'] = True
        
        # Range narrowing
        if len(closes) >= 30:
            range_30d = max(highs[-30:]) - min(lows[-30:])
            range_10d = max(highs[-10:]) - min(lows[-10:])
            if range_10d < range_30d * 0.5:
                patterns['narrowing_range'] = True
        
        return patterns
    
    def calculate_technicals(self, price_data: List[Dict]) -> Dict:
        """Calculate technical indicators"""
        print(f"  üìà Calculating technical indicators...")
        
        technicals = {
            # RSI
            'rsi_14_min': 0,
            'rsi_14_max': 0,
            'rsi_14_avg': 0,
            'rsi_oversold_days': 0,
            'rsi_overbought_days': 0,
            'rsi_at_entry': 0,
            
            # MACD
            'macd_bullish_cross': False,
            'macd_histogram_expansion': False,
            
            # Bollinger Bands
            'bb_squeeze_days': 0,
            'bb_walk_lower': False,
            'bb_breakout_upper': False,
            
            # Moving Averages
            'ma_20_cross': False,
            'ma_50_cross': False,
            'golden_cross': False,
            'price_above_all_ma': False
        }
        
        if len(price_data) < 14:
            return technicals
        
        closes = [d.get('c', 0) for d in price_data]
        
        # Calculate RSI
        rsi_values = self.calculate_rsi(closes, 14)
        if rsi_values:
            technicals['rsi_14_min'] = min(rsi_values)
            technicals['rsi_14_max'] = max(rsi_values)
            technicals['rsi_14_avg'] = sum(rsi_values) / len(rsi_values)
            technicals['rsi_at_entry'] = rsi_values[-1] if rsi_values else 50
            technicals['rsi_oversold_days'] = sum(1 for r in rsi_values if r < 30)
            technicals['rsi_overbought_days'] = sum(1 for r in rsi_values if r > 70)
        
        # Simple Moving Average checks
        if len(closes) >= 20:
            ma20 = sum(closes[-20:]) / 20
            if closes[-1] > ma20:
                technicals['ma_20_cross'] = True
        
        if len(closes) >= 50:
            ma50 = sum(closes[-50:]) / 50
            if closes[-1] > ma50:
                technicals['ma_50_cross'] = True
            
            # Check if price above all MAs
            if closes[-1] > ma20 and closes[-1] > ma50:
                technicals['price_above_all_ma'] = True
        
        # Bollinger Bands (simplified)
        if len(closes) >= 20:
            ma20 = sum(closes[-20:]) / 20
            std_dev = self.calculate_std_dev(closes[-20:])
            upper_band = ma20 + (std_dev * 2)
            lower_band = ma20 - (std_dev * 2)
            
            # Check for squeeze (low volatility)
            band_width = (upper_band - lower_band) / ma20
            if band_width < 0.10:  # Narrow bands
                technicals['bb_squeeze_days'] += 1
            
            # Check for breakouts
            if closes[-1] > upper_band:
                technicals['bb_breakout_upper'] = True
            if closes[-1] < lower_band * 1.02:  # Near lower band
                technicals['bb_walk_lower'] = True
        
        return technicals
    
    def calculate_rsi(self, prices: List[float], period: int = 14) -> List[float]:
        """Calculate RSI values"""
        if len(prices) < period + 1:
            return []
        
        rsi_values = []
        gains = []
        losses = []
        
        # Calculate initial gains/losses
        for i in range(1, len(prices)):
            diff = prices[i] - prices[i-1]
            if diff > 0:
                gains.append(diff)
                losses.append(0)
            else:
                gains.append(0)
                losses.append(abs(diff))
        
        # Calculate RSI for each point after we have enough data
        for i in range(period, len(gains) + 1):
            avg_gain = sum(gains[i-period:i]) / period if i >= period else 0
            avg_loss = sum(losses[i-period:i]) / period if i >= period else 0
            
            if avg_loss == 0:
                rsi = 100
            else:
                rs = avg_gain / avg_loss
                rsi = 100 - (100 / (1 + rs))
            
            rsi_values.append(rsi)
        
        return rsi_values
    
    def calculate_std_dev(self, values: List[float]) -> float:
        """Calculate standard deviation"""
        if not values:
            return 0
        mean = sum(values) / len(values)
        variance = sum((x - mean) ** 2 for x in values) / len(values)
        return variance ** 0.5
    
    def analyze_market_context(self, ticker: str, entry_date: str, stock_data: List[Dict]) -> Dict:
        """Analyze performance vs market (SPY/QQQ)"""
        print(f"  üìä Analyzing market context...")
        
        context = {
            'spy_correlation': 0,
            'spy_outperformance': 0,
            'qqq_correlation': 0,
            'qqq_outperformance': 0,
            'relative_strength': 0,
            'market_regime': 'unknown'
        }
        
        # Get SPY data for comparison
        spy_data = self.get_price_data('SPY', entry_date, 90)
        
        if spy_data and stock_data:
            # Calculate returns
            stock_returns = self.calculate_returns([d.get('c', 0) for d in stock_data])
            spy_returns = self.calculate_returns([d.get('c', 0) for d in spy_data])
            
            if stock_returns and spy_returns:
                # Calculate outperformance
                stock_total_return = (stock_data[-1].get('c', 0) / stock_data[0].get('c', 1) - 1) * 100 if stock_data else 0
                spy_total_return = (spy_data[-1].get('c', 0) / spy_data[0].get('c', 1) - 1) * 100 if spy_data else 0
                context['spy_outperformance'] = stock_total_return - spy_total_return
                
                # Simple correlation (would use numpy in production)
                if len(stock_returns) == len(spy_returns):
                    context['spy_correlation'] = self.simple_correlation(stock_returns, spy_returns)
                
                # Relative strength
                if spy_total_return != 0:
                    context['relative_strength'] = stock_total_return / spy_total_return
        
        # Determine market regime
        if context['spy_outperformance'] > 20:
            context['market_regime'] = 'outperforming'
        elif context['spy_outperformance'] < -10:
            context['market_regime'] = 'underperforming'
        else:
            context['market_regime'] = 'inline'
        
        # QQQ analysis (simplified for test)
        context['qqq_correlation'] = context['spy_correlation'] * 0.9  # Approximate
        context['qqq_outperformance'] = context['spy_outperformance'] * 0.8  # Approximate
        
        return context
    
    def calculate_returns(self, prices: List[float]) -> List[float]:
        """Calculate daily returns"""
        returns = []
        for i in range(1, len(prices)):
            if prices[i-1] != 0:
                returns.append((prices[i] / prices[i-1] - 1))
        return returns
    
    def simple_correlation(self, x: List[float], y: List[float]) -> float:
        """Calculate simple correlation coefficient"""
        if len(x) != len(y) or len(x) == 0:
            return 0
        
        # Simple correlation calculation (would use numpy in production)
        n = len(x)
        sum_x = sum(x)
        sum_y = sum(y)
        sum_xy = sum(x[i] * y[i] for i in range(n))
        sum_x2 = sum(xi ** 2 for xi in x)
        sum_y2 = sum(yi ** 2 for yi in y)
        
        denom = ((n * sum_x2 - sum_x ** 2) * (n * sum_y2 - sum_y ** 2)) ** 0.5
        if denom == 0:
            return 0
        
        return (n * sum_xy - sum_x * sum_y) / denom
    
    def calculate_pattern_scores(self, price_volume: Dict, technicals: Dict, market: Dict) -> Dict:
        """Calculate composite pattern scores"""
        print(f"  üéØ Calculating pattern scores...")
        
        scores = {
            'volume_score': 0,
            'technical_score': 0,
            'momentum_score': 0,
            'market_score': 0,
            'total_score': 0,
            'signal_strength': 'WEAK',
            'has_primary_signal': False,
            'primary_signal_count': 0,
            'secondary_signal_count': 0
        }
        
        # Volume score (0-100)
        if price_volume.get('volume_10x_spike'):
            scores['volume_score'] = 100
            scores['primary_signal_count'] += 1
        elif price_volume.get('volume_5x_spike'):
            scores['volume_score'] = 80
            scores['primary_signal_count'] += 1
        elif price_volume.get('volume_3x_spike'):
            scores['volume_score'] = 60
            scores['secondary_signal_count'] += 1
        elif price_volume.get('volume_spike_count', 0) > 2:
            scores['volume_score'] = 40
        
        # Technical score (0-100)
        technical_points = 0
        if technicals.get('rsi_oversold_days', 0) > 0:
            technical_points += 30
            scores['secondary_signal_count'] += 1
        if technicals.get('ma_20_cross'):
            technical_points += 20
        if technicals.get('bb_squeeze_days', 0) > 5:
            technical_points += 20
        if technicals.get('price_above_all_ma'):
            technical_points += 30
        scores['technical_score'] = min(100, technical_points)
        
        # Momentum score
        if price_volume.get('breakout_20d_high'):
            scores['momentum_score'] += 40
        if price_volume.get('higher_lows_count', 0) >= 3:
            scores['momentum_score'] += 30
        if price_volume.get('accumulation_detected'):
            scores['momentum_score'] += 30
        
        # Market score
        if market.get('spy_outperformance', 0) > 20:
            scores['market_score'] = 60
            scores['secondary_signal_count'] += 1
        elif market.get('spy_outperformance', 0) > 10:
            scores['market_score'] = 40
        elif market.get('spy_outperformance', 0) > 0:
            scores['market_score'] = 20
        
        # Calculate total score (weighted)
        scores['total_score'] = (
            scores['volume_score'] * 0.35 +
            scores['technical_score'] * 0.25 +
            scores['momentum_score'] * 0.20 +
            scores['market_score'] * 0.20
        )
        
        # Determine signal strength
        scores['has_primary_signal'] = scores['primary_signal_count'] > 0
        
        if scores['primary_signal_count'] >= 1:
            scores['signal_strength'] = 'PRIMARY'
        elif scores['secondary_signal_count'] >= 2:
            scores['signal_strength'] = 'SECONDARY'
        elif scores['total_score'] >= 50:
            scores['signal_strength'] = 'MEDIUM'
        else:
            scores['signal_strength'] = 'WEAK'
        
        return scores


def analyze_batch(stocks: List[Dict], batch_id: str, output_dir: str = 'Verified_Backtest_Data'):
    """
    Analyze a batch of stocks and save results
    """
    print(f"\n{'='*60}")
    print(f"BATCH {batch_id} ANALYSIS")
    print(f"{'='*60}")
    print(f"Stocks to analyze: {len(stocks)}")
    print(f"Output directory: {output_dir}")
    
    # Create output directory
    os.makedirs(output_dir, exist_ok=True)
    
    # Initialize analyzer
    analyzer = ComprehensiveStockAnalyzer()
    
    # Results container
    results = {
        'batch_id': batch_id,
        'analysis_date': datetime.now().isoformat(),
        'total_stocks': len(stocks),
        'stocks_analyzed': [],
        'summary_stats': {}
    }
    
    # Analyze each stock
    for i, stock in enumerate(stocks, 1):
        ticker = stock.get('ticker', 'UNKNOWN')
        print(f"\n[{i}/{len(stocks)}] Processing {ticker}...")
        
        # Analyze stock
        stock_analysis = analyzer.analyze_stock(stock)
        results['stocks_analyzed'].append(stock_analysis)
        
        # Rate limiting
        time.sleep(0.5)  # Be nice to API
    
    # Calculate summary statistics
    successful = sum(1 for s in results['stocks_analyzed'] if s['analysis_status'] == 'complete')
    
    results['summary_stats'] = {
        'successful_analyses': successful,
        'failed_analyses': len(stocks) - successful,
        'success_rate': (successful / len(stocks) * 100) if stocks else 0,
        'patterns_found': {
            'volume_3x_spike': sum(1 for s in results['stocks_analyzed'] 
                                   if s.get('price_volume_patterns', {}).get('volume_3x_spike')),
            'rsi_oversold': sum(1 for s in results['stocks_analyzed'] 
                               if s.get('technical_indicators', {}).get('rsi_oversold_days', 0) > 0),
            'breakout_pattern': sum(1 for s in results['stocks_analyzed'] 
                                   if s.get('price_volume_patterns', {}).get('breakout_20d_high')),
            'market_outperform': sum(1 for s in results['stocks_analyzed'] 
                                    if s.get('market_context', {}).get('spy_outperformance', 0) > 20)
        }
    }
    
    # Save results
    output_file = os.path.join(output_dir, f'phase3_batch_{batch_id}_analysis.json')
    with open(output_file, 'w') as f:
        json.dump(results, f, indent=2)
    
    print(f"\n{'='*60}")
    print(f"BATCH {batch_id} COMPLETE")
    print(f"{'='*60}")
    print(f"‚úÖ Analyzed: {successful}/{len(stocks)} stocks")
    print(f"üìä Patterns found:")
    for pattern, count in results['summary_stats']['patterns_found'].items():
        print(f"  - {pattern}: {count} stocks")
    print(f"üíæ Results saved: {output_file}")
    
    return results


def main():
    """
    Main entry point for batch analysis
    """
    if len(sys.argv) < 3:
        print("Usage: python phase3_comprehensive_collector.py <batch_id> <stocks_file>")
        print("Example: python phase3_comprehensive_collector.py batch1 batch1_stocks.json")
        sys.exit(1)
    
    batch_id = sys.argv[1]
    stocks_file = sys.argv[2]
    
    # Load stocks
    if not os.path.exists(stocks_file):
        print(f"Error: File not found: {stocks_file}")
        sys.exit(1)
    
    with open(stocks_file, 'r') as f:
        stocks_data = json.load(f)
    
    # Handle nested structure
    if isinstance(stocks_data, dict):
        stocks = stocks_data.get('stocks', [])
    else:
        stocks = stocks_data
    
    if not stocks:
        print("Error: No stocks found in file")
        sys.exit(1)
    
    # Analyze batch
    results = analyze_batch(stocks, batch_id)
    
    print(f"\n‚úÖ Batch {batch_id} analysis complete!")
    print(f"Successful: {results['summary_stats']['successful_analyses']}/{len(stocks)}")


if __name__ == '__main__':
    main()
